{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, ConcatDataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from spn.experiments.RandomSPNs_layerwise.rat_spn import RatSpn, RatSpnConfig\n",
    "from spn.experiments.RandomSPNs_layerwise.distributions import RatNormal\n",
    "from spn.algorithms.layerwise.distributions import Bernoulli\n",
    "from utils.datasets import gen_dataset\n",
    "from utils.config_utils import load_config_data\n",
    "from utils.utils import visualize_3d\n",
    "from utils.selectors import get_sim_dataloader\n",
    "from constraint.constraints import GeneralizationConstraint\n",
    "import time\n",
    "import argparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spn(S, I, R, D, F, C, device, leaf_base_class) -> RatSpn:\n",
    "        \"\"\"Construct the RatSpn\"\"\"\n",
    "\n",
    "        # Setup RatSpnConfig\n",
    "        config = RatSpnConfig()\n",
    "        config.F = F\n",
    "        config.R = R\n",
    "        config.D = D\n",
    "        config.I = I\n",
    "        config.S = S\n",
    "        config.C = C\n",
    "        config.dropout = 0.0\n",
    "        config.leaf_base_class = leaf_base_class \n",
    "        config.leaf_base_kwargs = {}\n",
    "\n",
    "        # Construct RatSpn from config\n",
    "        model = RatSpn(config)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        print(\"Using device:\", device)\n",
    "        return model\n",
    "\n",
    "\n",
    "def get_adult_loaders(use_cuda, batch_size):\n",
    "    df = pd.read_csv(\"..\\\\data\\\\Adult\\\\train_0.csv\").astype(float)\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() > 2:\n",
    "            d  = KBinsDiscretizer(n_bins=2, encode='ordinal',strategy='kmeans')\n",
    "            df[col] = d.fit_transform(df[col].to_numpy().reshape(-1, 1)).flatten().astype(int)\n",
    "    print (df.nunique())\n",
    "    kwargs = {\"num_workers\": 8, \"pin_memory\": True} if use_cuda else {}\n",
    "\n",
    "    test_batch_size = batch_size\n",
    "\n",
    "    train, test = train_test_split(df, stratify=df.income, random_state=0)\n",
    "    # Train data loader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TensorDataset(torch.Tensor(train.to_numpy())),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Test data loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        TensorDataset(torch.Tensor(test.to_numpy())),\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                               2\n",
      "education-num                     2\n",
      "capital-gain                      2\n",
      "capital-loss                      2\n",
      "hours-per-week                    2\n",
      "                                 ..\n",
      "native-country_Trinadad&Tobago    2\n",
      "native-country_United-States      2\n",
      "native-country_Vietnam            2\n",
      "native-country_Yugoslavia         2\n",
      "income                            2\n",
      "Length: 87, dtype: int64\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_adult_loaders(False, 32)\n",
    "rat_S, rat_I, rat_D, rat_R, rat_C, leaves = 20, 20, 5, 5, 1, Bernoulli #RatNormal\n",
    "n_features = train_loader.dataset[0][0].shape[0]\n",
    "device=\"cpu\"\n",
    "dropout=0\n",
    "model = make_spn(S=rat_S, I=rat_I, D=rat_D, R=rat_R, device=device, F=n_features, C=rat_C,leaf_base_class=leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.05it/s]\n",
      "10it [00:09,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.5193, 0.0101, 0.1640, 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.4369, -0.0209, 0.0928, 0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.7810, -0.0024, 0.0523, 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.8649, -0.2807, 0.0457, 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.3221, 0.0358, 0.0038, 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.2538, 0.1138, 0.0016, 0.5717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.4110, 0.1270, 0.0000, 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.5266, -0.0522, 0.0000, nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epsilon = 0.001\n",
    "\n",
    "def penalty(model, data, epsilon):\n",
    "    y = data[:, -1].clone()\n",
    "    data0 = data.clone()\n",
    "    data0[:, -1] = 0\n",
    "    logp0 = model(data0)\n",
    "    denom = model(data0, (86,))\n",
    "    p0 = torch.exp(logp0 - denom).ravel()\n",
    "    delta = p0 - 0.5 + epsilon\n",
    "    return torch.square(torch.maximum(y*(delta), torch.zeros_like(y))).sum()\n",
    "\n",
    "model.train()\n",
    "prev_loss, total_loss = 0, 0\n",
    "prev_penalty, total_penalty = 0, 0\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "t = 1\n",
    "from itertools import islice\n",
    "for iteration in range(10):    \n",
    "    total_loss, total_penalty = 0, 0\n",
    "    for (data,) in tqdm(islice(train_loader,10)):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        zeta = penalty(model, data, epsilon)\n",
    "        lambda_ = 10**t\n",
    "        loss = -outputs.sum() / data.shape[0] + lambda_*zeta\n",
    "        total_loss += loss\n",
    "        total_penalty += zeta\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if iteration > 0:\n",
    "        rel_change_loss = (prev_loss - total_loss) / prev_loss\n",
    "        rel_change_penalty = (prev_penalty - total_penalty) / prev_penalty\n",
    "        print (f\"{total_loss:.4f}, {rel_change_loss:.4f}, {total_penalty:.4f}, {rel_change_penalty:.4f}\")\n",
    "        if rel_change_loss < 1e-4 :\n",
    "            if total_penalty != 0 and rel_change_penalty > 1e-4:\n",
    "                t = t + 1\n",
    "            else:\n",
    "                break\n",
    "    prev_loss = total_loss \n",
    "    prev_penalty = total_penalty\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
